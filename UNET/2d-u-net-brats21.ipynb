{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport cv2\nimport glob\nimport PIL\nimport shutil\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom skimage import data\nfrom skimage.util import montage \nimport skimage.transform as skTrans\nfrom skimage.transform import rotate\nfrom skimage.transform import resize\nfrom PIL import Image, ImageOps  \n\n# neural imaging\nimport nilearn as nl\nimport nibabel as nib\nimport nilearn.plotting as nlplt\n\n\n# ml libs\nimport keras\nimport keras.backend as K\nfrom keras.callbacks import CSVLogger\nimport tensorflow as tf\nfrom tensorflow.keras.utils import plot_model\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\nfrom tensorflow.keras.models import *\nfrom tensorflow.keras.layers import *\nfrom tensorflow.keras.optimizers import *\nfrom tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping, TensorBoard\nfrom tensorflow.keras.layers.experimental import preprocessing\n\n\n# Make numpy printouts easier to read.\nnp.set_printoptions(precision=3, suppress=True)","metadata":{"id":"epSn0XvegANV","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# DEFINE seg-areas  \nSEGMENT_CLASSES = {\n    0 : 'NOT tumor',   \n    1 : 'NECROTIC/CORE', # or NON-ENHANCING tumor CORE - RED\n    2 : 'EDEMA',  # Green\n    3 : 'ENHANCING' # original 4 -> converted into 3 later, Yellow\n}\n\n# there are 155 slices per volume\n# to start at 5 and use 145 slices means we will skip the first 5 and last 5 \nVOLUME_SLICES = 100 \nVOLUME_START_AT = 22 # first slice of volume that we will include\n\nIMG_SIZE=128","metadata":{"id":"eLSnyB2xi5rc","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tarfile\nfile = tarfile.open('../input/brats-2021-task1/BraTS2021_Training_Data.tar')\n\nfile.extractall('./BraTS2021_Training_Data')\nfile.close()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"file = tarfile.open('../input/brats-2021-task1/BraTS2021_00621.tar')\n\nfile.extractall('./sample_img')\nfile.close()\n\nnSample = os.listdir('./sample_img')\nnSample\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"TRAIN_DATASET_PATH = './BraTS2021_Training_Data/'","metadata":{"id":"JxAtml6VjH2y","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"nSample = os.listdir(TRAIN_DATASET_PATH + 'BraTS2021_01261')\nnSample","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_image_flair=nib.load(TRAIN_DATASET_PATH + 'BraTS2021_01261/BraTS2021_01261_flair.nii.gz').get_fdata()\ntest_image_t1=nib.load(TRAIN_DATASET_PATH + 'BraTS2021_01261/BraTS2021_01261_t1.nii.gz').get_fdata()\ntest_image_t1ce=nib.load(TRAIN_DATASET_PATH + 'BraTS2021_01261/BraTS2021_01261_t1ce.nii.gz').get_fdata()\ntest_image_t2=nib.load(TRAIN_DATASET_PATH + 'BraTS2021_01261/BraTS2021_01261_t2.nii.gz').get_fdata()\ntest_mask=nib.load(TRAIN_DATASET_PATH + 'BraTS2021_01261/BraTS2021_01261_seg.nii.gz').get_fdata()","metadata":{"id":"EpWEBjNFjk5j","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, (ax1, ax2, ax3, ax4, ax5) = plt.subplots(1,5, figsize = (20, 10))\nslice_w = 25\nax1.imshow(test_image_flair[:,:,test_image_flair.shape[0]//2-slice_w], cmap = 'gray')\nax1.set_title('Image flair')\nax2.imshow(test_image_t1[:,:,test_image_t1.shape[0]//2-slice_w], cmap = 'gray')\nax2.set_title('Image t1')\nax3.imshow(test_image_t1ce[:,:,test_image_t1ce.shape[0]//2-slice_w], cmap = 'gray')\nax3.set_title('Image t1ce')\nax4.imshow(test_image_t2[:,:,test_image_t2.shape[0]//2-slice_w], cmap = 'gray')\nax4.set_title('Image t2')\nax5.imshow(test_mask[:,:,test_mask.shape[0]//2-slice_w])\nax5.set_title('Mask')","metadata":{"id":"FbSEFiSlk-qW","outputId":"c653f9ae-70fc-432b-9e3f-d25abafa90f0","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax1 = plt.subplots(1, 1, figsize = (15,15))\nax1.imshow(rotate(montage(test_image_t1[50:-50,:,:]), 90, resize=True), cmap ='gray')","metadata":{"id":"XxL-GB0TlZUz","outputId":"26272267-a154-40a3-d31a-3dce1d30db41","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax1 = plt.subplots(1, 1, figsize = (15,15))\nax1.imshow(rotate(montage(test_mask[60:-60,:,:]), 90, resize=True), cmap ='gray')","metadata":{"id":"k5py1Ka3leWj","outputId":"6590c206-18db-4878-d794-49bbbafc4833","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"niimg = nl.image.load_img(TRAIN_DATASET_PATH + 'BraTS2021_01261/BraTS2021_01261_flair.nii.gz')\nnimask = nl.image.load_img(TRAIN_DATASET_PATH + 'BraTS2021_01261/BraTS2021_01261_seg.nii.gz')\n\nfig, axes = plt.subplots(nrows=4, figsize=(30, 40))\n\n\nnlplt.plot_anat(niimg,\n                title='BraTS18_Training_001_flair.nii plot_anat',\n                axes=axes[0])\n\nnlplt.plot_epi(niimg,\n               title='BraTS18_Training_001_flair.nii plot_epi',\n               axes=axes[1])\n\nnlplt.plot_img(niimg,\n               title='BraTS18_Training_001_flair.nii plot_img',\n               axes=axes[2])\n\nnlplt.plot_roi(nimask, \n               title='BraTS18_Training_001_flair.nii with mask plot_roi',\n               bg_img=niimg, \n               axes=axes[3], cmap='Paired')\n\nplt.show()","metadata":{"id":"0dg9dpFjlh0L","outputId":"df3fae64-81c9-4488-e64a-bb4b218840f3","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# dice loss as defined above for 4 classes\ndef dice_coef(y_true, y_pred, smooth=1.0):\n    class_num = 4\n    for i in range(class_num):\n        y_true_f = K.flatten(y_true[:,:,:,i])\n        y_pred_f = K.flatten(y_pred[:,:,:,i])\n        intersection = K.sum(y_true_f * y_pred_f)\n        loss = ((2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth))\n   #     K.print_tensor(loss, message='loss value for class {} : '.format(SEGMENT_CLASSES[i]))\n        if i == 0:\n            total_loss = loss\n        else:\n            total_loss = total_loss + loss\n            \n    total_loss = total_loss / class_num\n#    K.print_tensor(total_loss, message=' total dice coef: ')\n    return total_loss\n\n\n \n# define per class evaluation of dice coef\n# inspired by https://github.com/keras-team/keras/issues/9395\ndef dice_coef_necrotic(y_true, y_pred, epsilon=1e-6):\n    intersection = K.sum(K.abs(y_true[:,:,:,1] * y_pred[:,:,:,1]))\n    return (2. * intersection) / (K.sum(K.square(y_true[:,:,:,1])) + K.sum(K.square(y_pred[:,:,:,1])) + epsilon)\n\ndef dice_coef_edema(y_true, y_pred, epsilon=1e-6):\n    intersection = K.sum(K.abs(y_true[:,:,:,2] * y_pred[:,:,:,2]))\n    return (2. * intersection) / (K.sum(K.square(y_true[:,:,:,2])) + K.sum(K.square(y_pred[:,:,:,2])) + epsilon)\n\ndef dice_coef_enhancing(y_true, y_pred, epsilon=1e-6):\n    intersection = K.sum(K.abs(y_true[:,:,:,3] * y_pred[:,:,:,3]))\n    return (2. * intersection) / (K.sum(K.square(y_true[:,:,:,3])) + K.sum(K.square(y_pred[:,:,:,3])) + epsilon)\n\n\n\n# Computing Precision \ndef precision(y_true, y_pred):\n        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n        precision = true_positives / (predicted_positives + K.epsilon())\n        return precision\n\n    \n# Computing Sensitivity      \ndef sensitivity(y_true, y_pred):\n    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n    return true_positives / (possible_positives + K.epsilon())\n\n\n# Computing Specificity\ndef specificity(y_true, y_pred):\n    true_negatives = K.sum(K.round(K.clip((1-y_true) * (1-y_pred), 0, 1)))\n    possible_negatives = K.sum(K.round(K.clip(1-y_true, 0, 1)))\n    return true_negatives / (possible_negatives + K.epsilon())","metadata":{"id":"7ARHKXiEmHe1","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def build_unet(inputs, ker_init, dropout):\n    conv1 = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(inputs)\n    conv1 = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv1)\n    \n    pool = MaxPooling2D(pool_size=(2, 2))(conv1)\n    conv = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(pool)\n    conv = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv)\n    \n    pool1 = MaxPooling2D(pool_size=(2, 2))(conv)\n    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(pool1)\n    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv2)\n    \n    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(pool2)\n    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv3)\n    \n    \n    pool4 = MaxPooling2D(pool_size=(2, 2))(conv3)\n    conv5 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(pool4)\n    conv5 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv5)\n    drop5 = Dropout(dropout)(conv5)\n\n    up7 = Conv2D(256, 2, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(UpSampling2D(size = (2,2))(drop5))\n    merge7 = concatenate([conv3,up7], axis = 3)\n    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(merge7)\n    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv7)\n\n    up8 = Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(UpSampling2D(size = (2,2))(conv7))\n    merge8 = concatenate([conv2,up8], axis = 3)\n    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(merge8)\n    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv8)\n\n    up9 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(UpSampling2D(size = (2,2))(conv8))\n    merge9 = concatenate([conv,up9], axis = 3)\n    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(merge9)\n    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv9)\n    \n    up = Conv2D(32, 2, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(UpSampling2D(size = (2,2))(conv9))\n    merge = concatenate([conv1,up], axis = 3)\n    conv = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(merge)\n    conv = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv)\n    \n    conv10 = Conv2D(4, (1,1), activation = 'softmax')(conv)\n    \n    return Model(inputs = inputs, outputs = conv10)\n\ninput_layer = Input((IMG_SIZE, IMG_SIZE, 2))\n\nmodel = build_unet(input_layer, 'he_normal', 0.2)\nmodel.compile(loss=\"categorical_crossentropy\", optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), metrics = ['accuracy',tf.keras.metrics.MeanIoU(num_classes=4), dice_coef, precision, sensitivity, specificity, dice_coef_necrotic, dice_coef_edema ,dice_coef_enhancing] )\n","metadata":{"id":"lNpSudj8mNRD","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_model(model, \n           show_shapes = True,\n           show_dtype=False,\n           show_layer_names = True, \n           rankdir = 'TB', \n           expand_nested = False, \n           dpi = 70)","metadata":{"id":"J8WTz-37mX6U","outputId":"48ed770e-c7c9-405a-f23c-d685490bdb36","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"id":"lwCIeRlymeCb","outputId":"6991938c-6bb8-4875-b390-b1a33d686b10","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# lists of directories with studies\ntrain_and_val_directories = [f.path for f in os.scandir(TRAIN_DATASET_PATH) if f.is_dir()]\n\n# file BraTS20_Training_355 has ill formatted name for for seg.nii file\n#train_and_val_directories.remove(TRAIN_DATASET_PATH+'BraTS20_Training_355')\n\n\ndef pathListIntoIds(dirList):\n    x = []\n    for i in range(0,len(dirList)):\n        x.append(dirList[i][dirList[i].rfind('/')+1:])\n    return x\n\ntrain_and_test_ids = pathListIntoIds(train_and_val_directories); \n\n    \ntrain_test_ids, val_ids = train_test_split(train_and_test_ids,test_size=0.2) \ntrain_ids, test_ids = train_test_split(train_test_ids,test_size=0.15) ","metadata":{"id":"zo1p0EbJmh6h","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_and_test_ids[0] ","metadata":{"id":"44azT1RILr_R","outputId":"eb82307e-ecbe-4e82-fff3-761a6f9be15d","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_ids[0]","metadata":{"id":"Czbyhq3kMHQJ","outputId":"a8f6c3b5-925e-4bc4-ee2e-542a4a2f12f0","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class DataGenerator(tf.keras.utils.Sequence):\n    'Generates data for Keras'\n    def __init__(self, list_IDs, dim=(IMG_SIZE,IMG_SIZE), batch_size = 1, n_channels = 2, shuffle=True):\n        'Initialization'\n        self.dim = dim\n        self.batch_size = batch_size\n        self.list_IDs = list_IDs\n        self.n_channels = n_channels\n        self.shuffle = shuffle\n        self.on_epoch_end()\n\n    def __len__(self):\n        'Denotes the number of batches per epoch'\n        return int(np.floor(len(self.list_IDs) / self.batch_size))\n\n    def __getitem__(self, index):\n        'Generate one batch of data'\n        # Generate indexes of the batch\n        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n\n        # Find list of IDs\n        Batch_ids = [self.list_IDs[k] for k in indexes]\n\n        # Generate data\n        X, y = self.__data_generation(Batch_ids)\n\n        return X, y\n\n    def on_epoch_end(self):\n        'Updates indexes after each epoch'\n        self.indexes = np.arange(len(self.list_IDs))\n        if self.shuffle == True:\n            np.random.shuffle(self.indexes)\n\n    def __data_generation(self, Batch_ids):\n        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n        # Initialization\n        X = np.zeros((self.batch_size*VOLUME_SLICES, *self.dim, self.n_channels))\n        y = np.zeros((self.batch_size*VOLUME_SLICES, 240, 240))\n        Y = np.zeros((self.batch_size*VOLUME_SLICES, *self.dim, 4))\n\n        \n        # Generate data\n        for c, i in enumerate(Batch_ids):\n            case_path = os.path.join(TRAIN_DATASET_PATH, i)\n\n            data_path = os.path.join(case_path, f'{i}_flair.nii.gz');\n            flair = nib.load(data_path).get_fdata()    \n\n            data_path = os.path.join(case_path, f'{i}_t1ce.nii.gz');\n            ce = nib.load(data_path).get_fdata()\n            \n            data_path = os.path.join(case_path, f'{i}_seg.nii.gz');\n            seg = nib.load(data_path).get_fdata()\n        \n            for j in range(VOLUME_SLICES):\n                X[j +VOLUME_SLICES*c,:,:,0] = cv2.resize(flair[:,:,j+VOLUME_START_AT], (IMG_SIZE, IMG_SIZE));\n                X[j +VOLUME_SLICES*c,:,:,1] = cv2.resize(ce[:,:,j+VOLUME_START_AT], (IMG_SIZE, IMG_SIZE));\n\n                y[j +VOLUME_SLICES*c] = seg[:,:,j+VOLUME_START_AT];\n                    \n        # Generate masks\n        y[y==4] = 3;\n        mask = tf.one_hot(y, 4);\n        Y = tf.image.resize(mask, (IMG_SIZE, IMG_SIZE));\n        return X/np.max(X), Y\n        \ntraining_generator = DataGenerator(train_ids)\nvalid_generator = DataGenerator(val_ids)\ntest_generator = DataGenerator(test_ids)","metadata":{"id":"Iq9ZCYrsmwdr","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(train_ids))\nprint(len(val_ids))\nprint(len(test_ids))","metadata":{"id":"t-hnTHVbm0tD","outputId":"147edb50-aa47-41c3-8a59-a78c9641733a","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# show number of data for each dir \ndef showDataLayout():\n    plt.bar([\"Train\",\"Valid\",\"Test\"],\n    [len(train_ids), len(val_ids), len(test_ids)], align='center',color=[ 'green','red', 'blue'])\n    plt.legend()\n\n    plt.ylabel('Number of images')\n    plt.title('Data distribution')\n    plt.savefig('data2018.png')\n    plt.show()\n    \nshowDataLayout()","metadata":{"id":"ldka-h8Em6NT","outputId":"e27800c5-1eb2-4e8e-d5e8-e3be3fad5c1a","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.callbacks import ModelCheckpoint, EarlyStopping\n\nfilepath=\"3D-UNet-2018-weights-improvement-{epoch:02d}-{val_accuracy:.3f}.hdf5\" \n\ncheckpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n\nearly_stop = EarlyStopping(monitor='val_loss', patience=3, verbose=1, restore_best_weights=True)\n\ncsv_logger = CSVLogger('training_2021_2D_UNet.log')\n\nhistory =  model.fit(training_generator,\n                    epochs=30,\n                    steps_per_epoch=len(train_ids),\n                    callbacks= [checkpoint, csv_logger, early_stop],\n                    validation_data = valid_generator\n                    )  ","metadata":{"id":"Twarmca4nEWL","outputId":"ee11fd25-140e-4d85-c903-d7ff221265d9","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save(\"model_2021_2D_UNet.h5\")","metadata":{"id":"-abCCMlXfqR2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"############ load trained model ################\nmodel = tf.keras.models.load_model('model_2021_2D_UNet.h5', \n                                   custom_objects={ 'accuracy' : tf.keras.metrics.MeanIoU(num_classes=4),\n                                                   \"dice_coef\": dice_coef,\n                                                   \"precision\": precision,\n                                                   \"sensitivity\":sensitivity,\n                                                   \"specificity\":specificity,\n                                                   \"dice_coef_necrotic\": dice_coef_necrotic,\n                                                   \"dice_coef_edema\": dice_coef_edema,\n                                                   \"dice_coef_enhancing\": dice_coef_enhancing\n                                                  }, compile=False)\n\nhistory = pd.read_csv('training_2021_2D_UNet.log', sep=',', engine='python')\n\nhist=history\n\n############### ########## ####### #######\n\n# hist=history.history\n\nacc=hist['accuracy']\nval_acc=hist['val_accuracy']\n\nepoch=range(len(acc))\n\nloss=hist['loss']\nval_loss=hist['val_loss']\n\ntrain_dice=hist['dice_coef']\nval_dice=hist['val_dice_coef']\n\nf,ax=plt.subplots(1,4,figsize=(16,8))\n\nax[0].plot(epoch,acc,'b',label='Training Accuracy')\nax[0].plot(epoch,val_acc,'r',label='Validation Accuracy')\nax[0].legend()\n\nax[1].plot(epoch,loss,'b',label='Training Loss')\nax[1].plot(epoch,val_loss,'r',label='Validation Loss')\nax[1].legend()\n\nax[2].plot(epoch,train_dice,'b',label='Training dice coef')\nax[2].plot(epoch,val_dice,'r',label='Validation dice coef')\nax[2].legend()\n\nax[3].plot(epoch,hist['mean_io_u'],'b',label='Training mean IOU')\nax[3].plot(epoch,hist['val_mean_io_u'],'r',label='Validation mean IOU')\nax[3].legend()\nplt.savefig('training_result_2018.png')\nplt.show()","metadata":{"id":"BA5Wh3ETfwaS","outputId":"f92d723c-4262-412b-fe8f-cdbe732f5bd8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# mri type must one of 1) flair 2) t1 3) t1ce 4) t2 ------- or even 5) seg\n# returns volume of specified study at `path`\ndef imageLoader(path):\n    image = nib.load(path).get_fdata()\n    X = np.zeros((self.batch_size*VOLUME_SLICES, *self.dim, self.n_channels))\n    for j in range(VOLUME_SLICES):\n        X[j +VOLUME_SLICES*c,:,:,0] = cv2.resize(image[:,:,j+VOLUME_START_AT], (IMG_SIZE, IMG_SIZE));\n        X[j +VOLUME_SLICES*c,:,:,1] = cv2.resize(ce[:,:,j+VOLUME_START_AT], (IMG_SIZE, IMG_SIZE));\n\n        y[j +VOLUME_SLICES*c] = seg[:,:,j+VOLUME_START_AT];\n    return np.array(image)\n\n\n# load nifti file at `path`\n# and load each slice with mask from volume\n# choose the mri type & resize to `IMG_SIZE`\ndef loadDataFromDir(path, list_of_files, mriType, n_images):\n    scans = []\n    masks = []\n    for i in list_of_files[:n_images]:\n        fullPath = glob.glob( i + '/*'+ mriType +'*')[0]\n        currentScanVolume = imageLoader(fullPath)\n        currentMaskVolume = imageLoader( glob.glob( i + '/*seg*')[0] ) \n        # for each slice in 3D volume, find also it's mask\n        for j in range(0, currentScanVolume.shape[2]):\n            scan_img = cv2.resize(currentScanVolume[:,:,j], dsize=(IMG_SIZE,IMG_SIZE), interpolation=cv2.INTER_AREA).astype('uint8')\n            mask_img = cv2.resize(currentMaskVolume[:,:,j], dsize=(IMG_SIZE,IMG_SIZE), interpolation=cv2.INTER_AREA).astype('uint8')\n            scans.append(scan_img[..., np.newaxis])\n            masks.append(mask_img[..., np.newaxis])\n    return np.array(scans, dtype='float32'), np.array(masks, dtype='float32')\n        \n#brains_list_test, masks_list_test = loadDataFromDir(VALIDATION_DATASET_PATH, test_directories, \"flair\", 5)","metadata":{"id":"WHzsHqCbf5l0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def predictByPath(case_path,case):\n    files = next(os.walk(case_path))[2]\n    X = np.empty((VOLUME_SLICES, IMG_SIZE, IMG_SIZE, 2))\n  #  y = np.empty((VOLUME_SLICES, IMG_SIZE, IMG_SIZE))\n\n   # /content/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_2013_10_1/Brats18_2013_10_1_flair.nii\n\n    #vol_path = os.path.join(case_path, f'BraTS20_Training_{case}_flair.nii');\n    vol_path = case_path + case + '_flair.nii';\n    flair=nib.load(vol_path).get_fdata()\n    \n    #vol_path = os.path.join(case_path, f'BraTS20_Training_{case}_t1ce.nii');\n    vol_path = case_path + case + '_t1ce.nii';\n    ce=nib.load(vol_path).get_fdata() \n    \n #   vol_path = os.path.join(case_path, f'BraTS20_Training_{case}_seg.nii');\n #   seg=nib.load(vol_path).get_fdata()  \n\n    \n    for j in range(VOLUME_SLICES):\n        X[j,:,:,0] = cv2.resize(flair[:,:,j+VOLUME_START_AT], (IMG_SIZE,IMG_SIZE))\n        X[j,:,:,1] = cv2.resize(ce[:,:,j+VOLUME_START_AT], (IMG_SIZE,IMG_SIZE))\n #       y[j,:,:] = cv2.resize(seg[:,:,j+VOLUME_START_AT], (IMG_SIZE,IMG_SIZE))\n        \n  #  model.evaluate(x=X,y=y[:,:,:,0], callbacks= callbacks)\n    return model.predict(X/np.max(X), verbose=1)\n\ndef showPredictsById(case, start_slice = 60):\n    path = TRAIN_DATASET_PATH + case + '/'\n\n    # TRAIN_DATASET_PATH + test_ids[0] + \"/\" + test_ids[0] + '_flair.nii'\n\n    gt = nib.load(path + case +'_seg.nii').get_fdata()\n    origImage = nib.load(path + case +'_flair.nii').get_fdata()\n    p = predictByPath(path,case)\n\n    core = p[:,:,:,1]\n    edema= p[:,:,:,2]\n    enhancing = p[:,:,:,3]\n\n    plt.figure(figsize=(18, 50))\n    f, axarr = plt.subplots(1,6, figsize = (18, 50)) \n\n    for i in range(6): # for each image, add brain background\n        axarr[i].imshow(cv2.resize(origImage[:,:,start_slice+VOLUME_START_AT], (IMG_SIZE, IMG_SIZE)), cmap=\"gray\", interpolation='none')\n    \n    axarr[0].imshow(cv2.resize(origImage[:,:,start_slice+VOLUME_START_AT], (IMG_SIZE, IMG_SIZE)), cmap=\"gray\")\n    axarr[0].title.set_text('Original image flair')\n    curr_gt=cv2.resize(gt[:,:,start_slice+VOLUME_START_AT], (IMG_SIZE, IMG_SIZE), interpolation = cv2.INTER_NEAREST)\n    axarr[1].imshow(curr_gt, cmap=\"Reds\", interpolation='none', alpha=0.3) # ,alpha=0.3,cmap='Reds'\n    axarr[1].title.set_text('Ground truth')\n    axarr[2].imshow(p[start_slice,:,:,1:4], cmap=\"Reds\", interpolation='none', alpha=0.3)\n    axarr[2].title.set_text('all classes')\n    axarr[3].imshow(edema[start_slice,:,:], cmap=\"OrRd\", interpolation='none', alpha=0.3)\n    axarr[3].title.set_text(f'{SEGMENT_CLASSES[1]} predicted')\n    axarr[4].imshow(core[start_slice,:,], cmap=\"OrRd\", interpolation='none', alpha=0.3)\n    axarr[4].title.set_text(f'{SEGMENT_CLASSES[2]} predicted')\n    axarr[5].imshow(enhancing[start_slice,:,], cmap=\"OrRd\", interpolation='none', alpha=0.3)\n    axarr[5].title.set_text(f'{SEGMENT_CLASSES[3]} predicted')\n    plt.savefig('Test_01.png')\n    plt.show()\n    \n    \nshowPredictsById(case=test_ids[0])\nshowPredictsById(case=test_ids[1])\nshowPredictsById(case=test_ids[2])\nshowPredictsById(case=test_ids[3])\nshowPredictsById(case=test_ids[4])\nshowPredictsById(case=test_ids[5])\nshowPredictsById(case=test_ids[6])","metadata":{"id":"cL0s-oAuf_EV","outputId":"fbf370e2-4981-4720-8b04-19f7056939cf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# /content/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_2013_10_1/Brats18_2013_10_1_flair.nii","metadata":{"id":"lXvnZpVoNr0z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_ids[0]","metadata":{"id":"ZfiGgYBdNOEh","outputId":"913c8a7b-fe66-4ff7-d0e0-83d1c1141046"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"TRAIN_DATASET_PATH + test_ids[0] + \"/\" + test_ids[0] + '_flair.nii'","metadata":{"id":"Q8RM4ws4NQAL","outputId":"3a07abb0-86e8-41f2-c434-ec6878f83e89"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"case = test_ids[4]\n# path = f\"../input/brats2018-dataset/MICCAI_BraTS_2018_Data_Training/Brats18_{case}\"\npath = TRAIN_DATASET_PATH + test_ids[4] + \"/\" \ngt = nib.load(path + test_ids[4] +'_seg.nii').get_fdata()\np = predictByPath(path,case)\n\n\ncore = p[:,:,:,1]\nedema= p[:,:,:,2]\nenhancing = p[:,:,:,3]\n\n\ni=40 # slice at\neval_class =3 #     0 : 'NOT tumor',  1 : 'ENHANCING',    2 : 'CORE',    3 : 'WHOLE'\n\n\n\ngt[gt != eval_class] = 1 # use only one class for per class evaluation \n\nresized_gt = cv2.resize(gt[:,:,i+VOLUME_START_AT], (IMG_SIZE, IMG_SIZE))\n\nplt.figure()\nf, axarr = plt.subplots(1,2) \naxarr[0].imshow(resized_gt, cmap=\"gray\")\naxarr[0].title.set_text('ground truth')\naxarr[1].imshow(p[i,:,:,eval_class], cmap=\"gray\")\naxarr[1].title.set_text(f'predicted class: {SEGMENT_CLASSES[eval_class]}')\nplt.show()","metadata":{"id":"2xxaZ1s3gDsP","outputId":"21e0a8f1-2ba5-4145-ff81-ac9eb05d22d3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"csv_logger = CSVLogger('./evaluation_50.log')\nmodel.compile(loss=\"categorical_crossentropy\", optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), metrics = ['accuracy',tf.keras.metrics.MeanIoU(num_classes=4), dice_coef, precision, sensitivity, specificity, dice_coef_necrotic, dice_coef_edema, dice_coef_enhancing] )\n# Evaluate the model on the test data using `evaluate`\nprint(\"Evaluate on test data\")\nresults = model.evaluate(test_generator, batch_size=100, callbacks= [csv_logger])\nprint(\"test loss, test acc:\", results)","metadata":{"id":"PZYaUl1_gGH_","outputId":"dba033cb-5213-4e34-d5c2-1245c6d5f746"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"6lHekC2UgIdH"},"execution_count":null,"outputs":[]}]}